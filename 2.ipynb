{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f35c398",
      "metadata": {
        "id": "5f35c398",
        "outputId": "e66bc0e0-b9f1-4c8b-9576-efc2e908f0ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Rate: 10.0%\n",
            "Epoch 0, Loss: 1.35629141330719\n",
            "Epoch 10, Loss: 0.800433337688446\n",
            "Epoch 20, Loss: 0.44208261370658875\n",
            "Epoch 30, Loss: 0.10981074720621109\n",
            "Epoch 40, Loss: 0.013080601580440998\n",
            "Epoch 50, Loss: 0.008519557304680347\n",
            "Epoch 60, Loss: 0.0007928858976811171\n",
            "Epoch 70, Loss: 0.00012372522905934602\n",
            "Epoch 80, Loss: 0.0006349781178869307\n",
            "Epoch 90, Loss: 0.0002861167013179511\n",
            "Epoch 100, Loss: 0.00012027110642520711\n",
            "Epoch 110, Loss: 0.00015538591833319515\n",
            "Epoch 120, Loss: 0.00012046741176163778\n",
            "Epoch 130, Loss: 0.0001373826089547947\n",
            "Epoch 140, Loss: 0.0002617818536236882\n",
            "Epoch 150, Loss: 0.00011860090307891369\n",
            "Epoch 160, Loss: 0.00012726329441647977\n",
            "Epoch 170, Loss: 9.106814832193777e-05\n",
            "Epoch 180, Loss: 0.00045651933760382235\n",
            "Epoch 190, Loss: 0.00015402813733089715\n",
            "KarateClub - Accuracy: 0.4800, F1 Score: 0.3229, NMI: 0.2066, ARI: 0.0961, Modularity: 0.0788\n",
            "Epoch 0, Loss: 1.9389008283615112\n",
            "Epoch 10, Loss: 1.8042570352554321\n",
            "Epoch 20, Loss: 1.5240356922149658\n",
            "Epoch 30, Loss: 1.1071008443832397\n",
            "Epoch 40, Loss: 0.7742158770561218\n",
            "Epoch 50, Loss: 0.48403337597846985\n",
            "Epoch 60, Loss: 0.2972390949726105\n",
            "Epoch 70, Loss: 0.18550802767276764\n",
            "Epoch 80, Loss: 0.14780846238136292\n",
            "Epoch 90, Loss: 0.11893265694379807\n",
            "Epoch 100, Loss: 0.06512720882892609\n",
            "Epoch 110, Loss: 0.032489415258169174\n",
            "Epoch 120, Loss: 0.027888376265764236\n",
            "Epoch 130, Loss: 0.0136561319231987\n",
            "Epoch 140, Loss: 0.012968294322490692\n",
            "Epoch 150, Loss: 0.008992851711809635\n",
            "Epoch 160, Loss: 0.008076890371739864\n",
            "Epoch 170, Loss: 0.007161135319620371\n",
            "Epoch 180, Loss: 0.0068961745128035545\n",
            "Epoch 190, Loss: 0.0051481639966368675\n",
            "Cora - Accuracy: 0.4375, F1 Score: 0.3999, NMI: 0.2464, ARI: 0.2102, Modularity: 0.3424\n",
            "Epoch 0, Loss: 1.7895256280899048\n",
            "Epoch 10, Loss: 1.7021026611328125\n",
            "Epoch 20, Loss: 1.4354723691940308\n",
            "Epoch 30, Loss: 0.921062171459198\n",
            "Epoch 40, Loss: 0.3824019134044647\n",
            "Epoch 50, Loss: 0.18497559428215027\n",
            "Epoch 60, Loss: 0.0894208773970604\n",
            "Epoch 70, Loss: 0.04587129130959511\n",
            "Epoch 80, Loss: 0.04624802991747856\n",
            "Epoch 90, Loss: 0.0494658388197422\n",
            "Epoch 100, Loss: 0.04552294313907623\n",
            "Epoch 110, Loss: 0.03135531023144722\n",
            "Epoch 120, Loss: 0.03412548825144768\n",
            "Epoch 130, Loss: 0.028145557269454002\n",
            "Epoch 140, Loss: 0.03476593643426895\n",
            "Epoch 150, Loss: 0.030668381601572037\n",
            "Epoch 160, Loss: 0.026632431894540787\n",
            "Epoch 170, Loss: 0.024375762790441513\n",
            "Epoch 180, Loss: 0.02162441797554493\n",
            "Epoch 190, Loss: 0.020590517669916153\n",
            "Citeseer - Accuracy: 0.4129, F1 Score: 0.3781, NMI: 0.1784, ARI: 0.1262, Modularity: 0.3936\n",
            "Epoch 0, Loss: 1.3934662342071533\n",
            "Epoch 10, Loss: 1.348682165145874\n",
            "Epoch 20, Loss: 1.3172188997268677\n",
            "Epoch 30, Loss: 0.9484716653823853\n",
            "Epoch 40, Loss: 0.7037757039070129\n",
            "Epoch 50, Loss: 0.57566237449646\n",
            "Epoch 60, Loss: 0.4963173568248749\n",
            "Epoch 70, Loss: 0.45592811703681946\n",
            "Epoch 80, Loss: 0.4212082028388977\n",
            "Epoch 90, Loss: 0.41001078486442566\n",
            "Epoch 100, Loss: 0.38328081369400024\n",
            "Epoch 110, Loss: 0.3876020014286041\n",
            "Epoch 120, Loss: 0.37003159523010254\n",
            "Epoch 130, Loss: 0.36019885540008545\n",
            "Epoch 140, Loss: 0.36329859495162964\n",
            "Epoch 150, Loss: 0.33700504899024963\n",
            "Epoch 160, Loss: 0.3462487459182739\n",
            "Epoch 170, Loss: 0.3334154188632965\n",
            "Epoch 180, Loss: 0.32451310753822327\n",
            "Epoch 190, Loss: 0.3142349421977997\n",
            "FacebookPagePage - Accuracy: 0.8424, F1 Score: 0.8319, NMI: 0.5785, ARI: 0.6361, Modularity: 0.5009\n",
            "--------------------------------------------------\n",
            "Label Rate: 20.0%\n",
            "Epoch 0, Loss: 1.3596324920654297\n",
            "Epoch 10, Loss: 0.704786479473114\n",
            "Epoch 20, Loss: 0.12457284331321716\n",
            "Epoch 30, Loss: 0.007679564878344536\n",
            "Epoch 40, Loss: 0.004560220520943403\n",
            "Epoch 50, Loss: 0.0005334788584150374\n",
            "Epoch 60, Loss: 0.000410733773605898\n",
            "Epoch 70, Loss: 0.00036172918044030666\n",
            "Epoch 80, Loss: 0.00047086659469641745\n",
            "Epoch 90, Loss: 0.00021820567781105638\n",
            "Epoch 100, Loss: 0.0006122845807112753\n",
            "Epoch 110, Loss: 0.001065982272848487\n",
            "Epoch 120, Loss: 0.0002743979566730559\n",
            "Epoch 130, Loss: 0.00028979944181628525\n",
            "Epoch 140, Loss: 0.0003463001048658043\n",
            "Epoch 150, Loss: 0.0001551193417981267\n",
            "Epoch 160, Loss: 0.0005485558067448437\n",
            "Epoch 170, Loss: 0.00013154825137462467\n",
            "Epoch 180, Loss: 0.0001575956557644531\n",
            "Epoch 190, Loss: 0.0001538470241939649\n",
            "KarateClub - Accuracy: 0.6818, F1 Score: 0.3943, NMI: 0.4217, ARI: 0.2633, Modularity: 0.2780\n",
            "Epoch 0, Loss: 1.9534517526626587\n",
            "Epoch 10, Loss: 1.8170912265777588\n",
            "Epoch 20, Loss: 1.6509736776351929\n",
            "Epoch 30, Loss: 1.2545467615127563\n",
            "Epoch 40, Loss: 0.8556023240089417\n",
            "Epoch 50, Loss: 0.6187046766281128\n",
            "Epoch 60, Loss: 0.35022425651550293\n",
            "Epoch 70, Loss: 0.26202112436294556\n",
            "Epoch 80, Loss: 0.20932312309741974\n",
            "Epoch 90, Loss: 0.1410341113805771\n",
            "Epoch 100, Loss: 0.08948881924152374\n",
            "Epoch 110, Loss: 0.06614752858877182\n",
            "Epoch 120, Loss: 0.042401786893606186\n",
            "Epoch 130, Loss: 0.04295845702290535\n",
            "Epoch 140, Loss: 0.03761831298470497\n",
            "Epoch 150, Loss: 0.02592483162879944\n",
            "Epoch 160, Loss: 0.017708929255604744\n",
            "Epoch 170, Loss: 0.023519210517406464\n",
            "Epoch 180, Loss: 0.02350641041994095\n",
            "Epoch 190, Loss: 0.013953919522464275\n",
            "Cora - Accuracy: 0.5289, F1 Score: 0.4905, NMI: 0.3133, ARI: 0.3021, Modularity: 0.4121\n",
            "Epoch 0, Loss: 1.797440528869629\n",
            "Epoch 10, Loss: 1.7253961563110352\n",
            "Epoch 20, Loss: 1.518712043762207\n",
            "Epoch 30, Loss: 1.0402610301971436\n",
            "Epoch 40, Loss: 0.6840950846672058\n",
            "Epoch 50, Loss: 0.33814895153045654\n",
            "Epoch 60, Loss: 0.2368994653224945\n",
            "Epoch 70, Loss: 0.20788651704788208\n",
            "Epoch 80, Loss: 0.19522725045681\n",
            "Epoch 90, Loss: 0.15806899964809418\n",
            "Epoch 100, Loss: 0.09001485258340836\n",
            "Epoch 110, Loss: 0.05597592517733574\n",
            "Epoch 120, Loss: 0.045864954590797424\n",
            "Epoch 130, Loss: 0.04453762248158455\n",
            "Epoch 140, Loss: 0.036627884954214096\n",
            "Epoch 150, Loss: 0.0394735261797905\n",
            "Epoch 160, Loss: 0.039624493569135666\n",
            "Epoch 170, Loss: 0.03363250568509102\n",
            "Epoch 180, Loss: 0.047315340489149094\n",
            "Epoch 190, Loss: 0.02970680594444275\n",
            "Citeseer - Accuracy: 0.4942, F1 Score: 0.4635, NMI: 0.2035, ARI: 0.1737, Modularity: 0.4895\n",
            "Epoch 0, Loss: 1.3954952955245972\n",
            "Epoch 10, Loss: 1.3512324094772339\n",
            "Epoch 20, Loss: 1.3275041580200195\n",
            "Epoch 30, Loss: 1.0218391418457031\n",
            "Epoch 40, Loss: 0.7192639708518982\n",
            "Epoch 50, Loss: 0.5792861580848694\n",
            "Epoch 60, Loss: 0.5094457268714905\n",
            "Epoch 70, Loss: 0.4559861719608307\n",
            "Epoch 80, Loss: 0.44434672594070435\n",
            "Epoch 90, Loss: 0.41872990131378174\n",
            "Epoch 100, Loss: 0.4086841642856598\n",
            "Epoch 110, Loss: 0.3931035101413727\n",
            "Epoch 120, Loss: 0.38885146379470825\n",
            "Epoch 130, Loss: 0.3901344835758209\n",
            "Epoch 140, Loss: 0.3728501498699188\n",
            "Epoch 150, Loss: 0.3855195641517639\n",
            "Epoch 160, Loss: 0.3691386878490448\n",
            "Epoch 170, Loss: 0.359756201505661\n",
            "Epoch 180, Loss: 0.3630329668521881\n",
            "Epoch 190, Loss: 0.34790974855422974\n",
            "FacebookPagePage - Accuracy: 0.8376, F1 Score: 0.8252, NMI: 0.5784, ARI: 0.6213, Modularity: 0.4853\n",
            "--------------------------------------------------\n",
            "Label Rate: 30.0%\n",
            "Epoch 0, Loss: 1.3544604778289795\n",
            "Epoch 10, Loss: 1.0785465240478516\n",
            "Epoch 20, Loss: 0.5863933563232422\n",
            "Epoch 30, Loss: 0.5217206478118896\n",
            "Epoch 40, Loss: 0.35454919934272766\n",
            "Epoch 50, Loss: 0.1350121796131134\n",
            "Epoch 60, Loss: 0.012326815165579319\n",
            "Epoch 70, Loss: 0.003059172537177801\n",
            "Epoch 80, Loss: 0.0007228991016745567\n",
            "Epoch 90, Loss: 0.00109351787250489\n",
            "Epoch 100, Loss: 0.00033410819014534354\n",
            "Epoch 110, Loss: 0.0008972469950094819\n",
            "Epoch 120, Loss: 9.533746197121218e-05\n",
            "Epoch 130, Loss: 0.00047736972919665277\n",
            "Epoch 140, Loss: 0.0013708726037293673\n",
            "Epoch 150, Loss: 0.00399370351806283\n",
            "Epoch 160, Loss: 0.00040822679875418544\n",
            "Epoch 170, Loss: 0.0009015257237479091\n",
            "Epoch 180, Loss: 0.00024078944989014417\n",
            "Epoch 190, Loss: 0.0008034347556531429\n",
            "KarateClub - Accuracy: 0.8333, F1 Score: 0.8506, NMI: 0.7135, ARI: 0.5058, Modularity: 0.3387\n",
            "Epoch 0, Loss: 1.9535175561904907\n",
            "Epoch 10, Loss: 1.824806571006775\n",
            "Epoch 20, Loss: 1.6466232538223267\n",
            "Epoch 30, Loss: 1.3007103204727173\n",
            "Epoch 40, Loss: 1.1286418437957764\n",
            "Epoch 50, Loss: 0.9107369184494019\n",
            "Epoch 60, Loss: 0.6589992046356201\n",
            "Epoch 70, Loss: 0.473605215549469\n",
            "Epoch 80, Loss: 0.385568767786026\n",
            "Epoch 90, Loss: 0.40790870785713196\n",
            "Epoch 100, Loss: 0.3746614456176758\n",
            "Epoch 110, Loss: 0.3008612394332886\n",
            "Epoch 120, Loss: 0.2782866656780243\n",
            "Epoch 130, Loss: 0.21042117476463318\n",
            "Epoch 140, Loss: 0.1767818033695221\n",
            "Epoch 150, Loss: 0.14867649972438812\n",
            "Epoch 160, Loss: 0.11676677316427231\n",
            "Epoch 170, Loss: 0.09240709245204926\n",
            "Epoch 180, Loss: 0.07869584113359451\n",
            "Epoch 190, Loss: 0.07066281884908676\n",
            "Cora - Accuracy: 0.6125, F1 Score: 0.5415, NMI: 0.3831, ARI: 0.4221, Modularity: 0.4604\n",
            "Epoch 0, Loss: 1.7833579778671265\n",
            "Epoch 10, Loss: 1.7439296245574951\n",
            "Epoch 20, Loss: 1.525866150856018\n",
            "Epoch 30, Loss: 1.0448697805404663\n",
            "Epoch 40, Loss: 0.6672427654266357\n",
            "Epoch 50, Loss: 0.31716200709342957\n",
            "Epoch 60, Loss: 0.14498984813690186\n",
            "Epoch 70, Loss: 0.0988662838935852\n",
            "Epoch 80, Loss: 0.08762181550264359\n",
            "Epoch 90, Loss: 0.06943660229444504\n",
            "Epoch 100, Loss: 0.05325186997652054\n",
            "Epoch 110, Loss: 0.05544126033782959\n",
            "Epoch 120, Loss: 0.03918517753481865\n",
            "Epoch 130, Loss: 0.045070890337228775\n",
            "Epoch 140, Loss: 0.04238581284880638\n",
            "Epoch 150, Loss: 0.03941407427191734\n",
            "Epoch 160, Loss: 0.03264652565121651\n",
            "Epoch 170, Loss: 0.03860624134540558\n",
            "Epoch 180, Loss: 0.026289496570825577\n",
            "Epoch 190, Loss: 0.028760291635990143\n",
            "Citeseer - Accuracy: 0.6076, F1 Score: 0.5791, NMI: 0.3244, ARI: 0.3199, Modularity: 0.5687\n",
            "Epoch 0, Loss: 1.394919514656067\n",
            "Epoch 10, Loss: 1.3534501791000366\n",
            "Epoch 20, Loss: 1.3166943788528442\n",
            "Epoch 30, Loss: 0.8442105650901794\n",
            "Epoch 40, Loss: 0.6510435342788696\n",
            "Epoch 50, Loss: 0.532514750957489\n",
            "Epoch 60, Loss: 0.4846588671207428\n",
            "Epoch 70, Loss: 0.4575543701648712\n",
            "Epoch 80, Loss: 0.4412297308444977\n",
            "Epoch 90, Loss: 0.43498551845550537\n",
            "Epoch 100, Loss: 0.42182183265686035\n",
            "Epoch 110, Loss: 0.412542462348938\n",
            "Epoch 120, Loss: 0.41501033306121826\n",
            "Epoch 130, Loss: 0.40120789408683777\n",
            "Epoch 140, Loss: 0.40240123867988586\n",
            "Epoch 150, Loss: 0.39923086762428284\n",
            "Epoch 160, Loss: 0.3925743103027344\n",
            "Epoch 170, Loss: 0.3995571434497833\n",
            "Epoch 180, Loss: 0.3947962522506714\n",
            "Epoch 190, Loss: 0.39114609360694885\n",
            "FacebookPagePage - Accuracy: 0.8450, F1 Score: 0.8326, NMI: 0.5875, ARI: 0.6459, Modularity: 0.5142\n",
            "--------------------------------------------------\n",
            "Label Rate: 50.0%\n",
            "Epoch 0, Loss: 1.3685503005981445\n",
            "Epoch 10, Loss: 1.2658445835113525\n",
            "Epoch 20, Loss: 0.5060321092605591\n",
            "Epoch 30, Loss: 0.2746994197368622\n",
            "Epoch 40, Loss: 0.08683700859546661\n",
            "Epoch 50, Loss: 0.003737203311175108\n",
            "Epoch 60, Loss: 0.0007360597955994308\n",
            "Epoch 70, Loss: 0.00038491759914904833\n",
            "Epoch 80, Loss: 0.0006715873023495078\n",
            "Epoch 90, Loss: 0.0003165614907629788\n",
            "Epoch 100, Loss: 0.0004033875302411616\n",
            "Epoch 110, Loss: 0.0004694808158092201\n",
            "Epoch 120, Loss: 9.621403296478093e-05\n",
            "Epoch 130, Loss: 0.0006954880664125085\n",
            "Epoch 140, Loss: 0.00032298523001372814\n",
            "Epoch 150, Loss: 0.0001544070109957829\n",
            "Epoch 160, Loss: 0.00011978358816122636\n",
            "Epoch 170, Loss: 0.00014943328278604895\n",
            "Epoch 180, Loss: 0.0003506841603666544\n",
            "Epoch 190, Loss: 0.00019600754603743553\n",
            "KarateClub - Accuracy: 1.0000, F1 Score: 1.0000, NMI: 1.0000, ARI: 1.0000, Modularity: 0.4156\n",
            "Epoch 0, Loss: 1.928423523902893\n",
            "Epoch 10, Loss: 1.8153040409088135\n",
            "Epoch 20, Loss: 1.6380410194396973\n",
            "Epoch 30, Loss: 1.3116035461425781\n",
            "Epoch 40, Loss: 1.0948288440704346\n",
            "Epoch 50, Loss: 0.810678243637085\n",
            "Epoch 60, Loss: 0.5903527140617371\n",
            "Epoch 70, Loss: 0.4407583177089691\n",
            "Epoch 80, Loss: 0.294708251953125\n",
            "Epoch 90, Loss: 0.20392297208309174\n",
            "Epoch 100, Loss: 0.11182788759469986\n",
            "Epoch 110, Loss: 0.0660175085067749\n",
            "Epoch 120, Loss: 0.0423920713365078\n",
            "Epoch 130, Loss: 0.037774890661239624\n",
            "Epoch 140, Loss: 0.026296311989426613\n",
            "Epoch 150, Loss: 0.02287355065345764\n",
            "Epoch 160, Loss: 0.015895254909992218\n",
            "Epoch 170, Loss: 0.012840884737670422\n",
            "Epoch 180, Loss: 0.014276523143053055\n",
            "Epoch 190, Loss: 0.011213565245270729\n",
            "Cora - Accuracy: 0.7306, F1 Score: 0.6952, NMI: 0.5110, ARI: 0.5348, Modularity: 0.5912\n",
            "Epoch 0, Loss: 1.785891056060791\n",
            "Epoch 10, Loss: 1.7481640577316284\n",
            "Epoch 20, Loss: 1.5149815082550049\n",
            "Epoch 30, Loss: 1.1497474908828735\n",
            "Epoch 40, Loss: 0.822532057762146\n",
            "Epoch 50, Loss: 0.4088559150695801\n",
            "Epoch 60, Loss: 0.21769863367080688\n",
            "Epoch 70, Loss: 0.1220778301358223\n",
            "Epoch 80, Loss: 0.0922534242272377\n",
            "Epoch 90, Loss: 0.07015802711248398\n",
            "Epoch 100, Loss: 0.05434035509824753\n",
            "Epoch 110, Loss: 0.06509073078632355\n",
            "Epoch 120, Loss: 0.04985247924923897\n",
            "Epoch 130, Loss: 0.04372837394475937\n",
            "Epoch 140, Loss: 0.042580608278512955\n",
            "Epoch 150, Loss: 0.03979651257395744\n",
            "Epoch 160, Loss: 0.045568592846393585\n",
            "Epoch 170, Loss: 0.045728009194135666\n",
            "Epoch 180, Loss: 0.04596751928329468\n",
            "Epoch 190, Loss: 0.04468429833650589\n",
            "Citeseer - Accuracy: 0.6797, F1 Score: 0.6501, NMI: 0.4029, ARI: 0.4105, Modularity: 0.5979\n",
            "Epoch 0, Loss: 1.3928947448730469\n",
            "Epoch 10, Loss: 1.3508533239364624\n",
            "Epoch 20, Loss: 1.3039970397949219\n",
            "Epoch 30, Loss: 0.8940168619155884\n",
            "Epoch 40, Loss: 0.6931037902832031\n",
            "Epoch 50, Loss: 0.5685402750968933\n",
            "Epoch 60, Loss: 0.5004618167877197\n",
            "Epoch 70, Loss: 0.4787670075893402\n",
            "Epoch 80, Loss: 0.44099968671798706\n",
            "Epoch 90, Loss: 0.4311487674713135\n",
            "Epoch 100, Loss: 0.41814690828323364\n",
            "Epoch 110, Loss: 0.4165986478328705\n",
            "Epoch 120, Loss: 0.4107873737812042\n",
            "Epoch 130, Loss: 0.4058529734611511\n",
            "Epoch 140, Loss: 0.398122638463974\n",
            "Epoch 150, Loss: 0.3952941298484802\n",
            "Epoch 160, Loss: 0.39685118198394775\n",
            "Epoch 170, Loss: 0.3921376168727875\n",
            "Epoch 180, Loss: 0.38782140612602234\n",
            "Epoch 190, Loss: 0.38539981842041016\n",
            "FacebookPagePage - Accuracy: 0.8515, F1 Score: 0.8408, NMI: 0.5967, ARI: 0.6556, Modularity: 0.5090\n",
            "--------------------------------------------------\n",
            "Label Rate: 100.0%\n",
            "Epoch 0, Loss: 1.378158450126648\n",
            "Epoch 10, Loss: 1.1744693517684937\n",
            "Epoch 20, Loss: 0.4366280734539032\n",
            "Epoch 30, Loss: 0.12379832565784454\n",
            "Epoch 40, Loss: 0.0020979573018848896\n",
            "Epoch 50, Loss: 0.0007769912481307983\n",
            "Epoch 60, Loss: 0.0003451145894359797\n",
            "Epoch 70, Loss: 0.00042223322088830173\n",
            "Epoch 80, Loss: 0.0002465077268425375\n",
            "Epoch 90, Loss: 0.0001648471225053072\n",
            "Epoch 100, Loss: 0.00022661597176920623\n",
            "Epoch 110, Loss: 0.00011912556510651484\n",
            "Epoch 120, Loss: 0.0001944228570209816\n",
            "Epoch 130, Loss: 5.323845107341185e-05\n",
            "Epoch 140, Loss: 0.00020815958851017058\n",
            "Epoch 150, Loss: 4.017973333247937e-05\n",
            "Epoch 160, Loss: 0.00015063742466736585\n",
            "Epoch 170, Loss: 0.0002463188429828733\n",
            "Epoch 180, Loss: 0.0003219713398721069\n",
            "Epoch 190, Loss: 6.650567956967279e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\AI-BIO\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "C:\\Users\\AI-BIO\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KarateClub - Accuracy: nan, F1 Score: nan, NMI: 1.0000, ARI: 1.0000, Modularity: 0.4156\n",
            "Epoch 0, Loss: 1.9352468252182007\n",
            "Epoch 10, Loss: 1.8277878761291504\n",
            "Epoch 20, Loss: 1.7248204946517944\n",
            "Epoch 30, Loss: 1.3537386655807495\n",
            "Epoch 40, Loss: 1.113628625869751\n",
            "Epoch 50, Loss: 0.8846286535263062\n",
            "Epoch 60, Loss: 0.6230180859565735\n",
            "Epoch 70, Loss: 0.42551836371421814\n",
            "Epoch 80, Loss: 0.27542680501937866\n",
            "Epoch 90, Loss: 0.16653156280517578\n",
            "Epoch 100, Loss: 0.11276726424694061\n",
            "Epoch 110, Loss: 0.08505015820264816\n",
            "Epoch 120, Loss: 0.06829806417226791\n",
            "Epoch 130, Loss: 0.051572080701589584\n",
            "Epoch 140, Loss: 0.04639146104454994\n",
            "Epoch 150, Loss: 0.03511280193924904\n",
            "Epoch 160, Loss: 0.03754771500825882\n",
            "Epoch 170, Loss: 0.028894320130348206\n",
            "Epoch 180, Loss: 0.03060859814286232\n",
            "Epoch 190, Loss: 0.028924129903316498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\AI-BIO\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "C:\\Users\\AI-BIO\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cora - Accuracy: nan, F1 Score: nan, NMI: 1.0000, ARI: 1.0000, Modularity: 0.6450\n",
            "Epoch 0, Loss: 1.7981971502304077\n",
            "Epoch 10, Loss: 1.7533625364303589\n",
            "Epoch 20, Loss: 1.6559280157089233\n",
            "Epoch 30, Loss: 1.150996208190918\n",
            "Epoch 40, Loss: 0.7727739214897156\n",
            "Epoch 50, Loss: 0.546930730342865\n",
            "Epoch 60, Loss: 0.39879605174064636\n",
            "Epoch 70, Loss: 0.29237309098243713\n",
            "Epoch 80, Loss: 0.22375203669071198\n",
            "Epoch 90, Loss: 0.17963387072086334\n",
            "Epoch 100, Loss: 0.14503319561481476\n",
            "Epoch 110, Loss: 0.1164504885673523\n",
            "Epoch 120, Loss: 0.10561570525169373\n",
            "Epoch 130, Loss: 0.09193026274442673\n",
            "Epoch 140, Loss: 0.0898958295583725\n",
            "Epoch 150, Loss: 0.08205628395080566\n",
            "Epoch 160, Loss: 0.07843373715877533\n",
            "Epoch 170, Loss: 0.07352157682180405\n",
            "Epoch 180, Loss: 0.0740336999297142\n",
            "Epoch 190, Loss: 0.06890919804573059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\AI-BIO\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "C:\\Users\\AI-BIO\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Citeseer - Accuracy: nan, F1 Score: nan, NMI: 1.0000, ARI: 1.0000, Modularity: 0.5635\n",
            "Epoch 0, Loss: 1.3849437236785889\n",
            "Epoch 10, Loss: 1.351935863494873\n",
            "Epoch 20, Loss: 1.2983276844024658\n",
            "Epoch 30, Loss: 0.9937758445739746\n",
            "Epoch 40, Loss: 0.8047879934310913\n",
            "Epoch 50, Loss: 0.6527915000915527\n",
            "Epoch 60, Loss: 0.5521327257156372\n",
            "Epoch 70, Loss: 0.4916626811027527\n",
            "Epoch 80, Loss: 0.4633161127567291\n",
            "Epoch 90, Loss: 0.43749964237213135\n",
            "Epoch 100, Loss: 0.42642003297805786\n",
            "Epoch 110, Loss: 0.41782695055007935\n",
            "Epoch 120, Loss: 0.41025811433792114\n",
            "Epoch 130, Loss: 0.40341079235076904\n",
            "Epoch 140, Loss: 0.407344788312912\n",
            "Epoch 150, Loss: 0.3978734314441681\n",
            "Epoch 160, Loss: 0.39045581221580505\n",
            "Epoch 170, Loss: 0.3857491910457611\n",
            "Epoch 180, Loss: 0.39240550994873047\n",
            "Epoch 190, Loss: 0.3778238296508789\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\AI-BIO\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\lib\\function_base.py:518: RuntimeWarning: Mean of empty slice.\n",
            "  avg = a.mean(axis, **keepdims_kw)\n",
            "C:\\Users\\AI-BIO\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FacebookPagePage - Accuracy: nan, F1 Score: nan, NMI: 1.0000, ARI: 1.0000, Modularity: 0.5135\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_add_pool\n",
        "from torch_geometric.datasets import KarateClub, Planetoid, FacebookPagePage\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import normalized_mutual_info_score, f1_score, accuracy_score, adjusted_rand_score\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "import numpy as np\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.conv = GCNConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "class RNNLayer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(RNNLayer, self).__init__()\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, (h_n, c_n) = self.rnn(x)\n",
        "        return x, (h_n, c_n)\n",
        "\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.attention = nn.Linear(in_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        weights = F.softmax(self.attention(x), dim=1)\n",
        "        return torch.sum(weights * x, dim=1)\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, gcn_input_dim, gcn_output_dim, rnn_input_dim, rnn_hidden_dim, rnn_num_layers, num_classes):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.gcn = GCNLayer(gcn_input_dim, gcn_output_dim)\n",
        "        self.rnn = RNNLayer(rnn_input_dim, rnn_hidden_dim, rnn_num_layers)\n",
        "        self.attention = AttentionLayer(rnn_hidden_dim)\n",
        "        self.fc = nn.Linear(rnn_hidden_dim, num_classes)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # GCN forward\n",
        "        x = self.gcn(x, edge_index)\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        # RNN forward\n",
        "        x, (h_n, c_n) = self.rnn(x)\n",
        "\n",
        "        # Attention Layer\n",
        "        x = self.attention(x)\n",
        "\n",
        "\n",
        "        x = self.fc(self.dropout(x))\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "def train(model, data, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def test(model, data):\n",
        "    model.eval()\n",
        "    logits, accs = model(data), []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "        preds = logits.max(1)[1].cpu().numpy()\n",
        "        labels = data.y.cpu().numpy()\n",
        "\n",
        "\n",
        "    accuracy = accuracy_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()])\n",
        "\n",
        "\n",
        "    f1 = f1_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()], average='macro')\n",
        "\n",
        "\n",
        "    nmi = normalized_mutual_info_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()])\n",
        "\n",
        "\n",
        "    ari = adjusted_rand_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()])\n",
        "\n",
        "\n",
        "    G = to_networkx(data)\n",
        "    communities = {i: preds[i] for i in range(len(preds))}\n",
        "    community_list = [[] for _ in range(data.num_classes)]\n",
        "    for node, community in communities.items():\n",
        "        community_list[community].append(node)\n",
        "    modularity = nx.algorithms.community.modularity(G, community_list)\n",
        "\n",
        "    return accuracy, f1, nmi, ari, modularity\n",
        "\n",
        "def load_data(dataset_name, label_rate):\n",
        "    if dataset_name == 'KarateClub':\n",
        "        data = KarateClub(transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "    elif dataset_name == 'FacebookPagePage':\n",
        "        data = FacebookPagePage(root='/tmp/FacebookPagePage', transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "    else:\n",
        "        data = Planetoid(root=f'/tmp/{dataset_name}', name=dataset_name, transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "\n",
        "\n",
        "    num_nodes = data.y.size(0)\n",
        "    indices = np.random.permutation(num_nodes)\n",
        "    train_size = int(num_nodes * label_rate)\n",
        "    val_size = int(num_nodes * 0.2)\n",
        "    test_size = num_nodes - train_size - val_size\n",
        "\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "    train_mask[indices[:train_size]] = True\n",
        "    val_mask[indices[train_size:train_size + val_size]] = True\n",
        "    test_mask[indices[train_size + val_size:]] = True\n",
        "\n",
        "    data.train_mask = train_mask\n",
        "    data.val_mask = val_mask\n",
        "    data.test_mask = test_mask\n",
        "\n",
        "    return data\n",
        "\n",
        "label_rates = [0.1, 0.2, 0.3, 0.5, 1.0]\n",
        "\n",
        "datasets = ['KarateClub', 'Cora', 'Citeseer', 'FacebookPagePage']\n",
        "for label_rate in label_rates:\n",
        "    print(f'Label Rate: {label_rate*100}%')\n",
        "    for dataset_name in datasets:\n",
        "        data = load_data(dataset_name, label_rate)\n",
        "\n",
        "\n",
        "        model = HybridModel(gcn_input_dim=data.num_node_features, gcn_output_dim=32,\n",
        "                            rnn_input_dim=32, rnn_hidden_dim=64, rnn_num_layers=2, num_classes=data.num_classes)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "        for epoch in range(200):\n",
        "            loss = train(model, data, optimizer, criterion)\n",
        "            if epoch % 10 == 0:\n",
        "                print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "\n",
        "        accuracy, f1, nmi, ari, modularity = evaluate(model, data)\n",
        "        print(f'{dataset_name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, NMI: {nmi:.4f}, ARI: {ari:.4f}, Modularity: {modularity:.4f}')\n",
        "    print('-' * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87ae2bcf",
      "metadata": {
        "id": "87ae2bcf",
        "outputId": "8785d816-41a2-4a9f-be2c-8761c6f87d09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Rate: 50.0%\n",
            "Epoch 0, Loss: 1.3711448907852173\n",
            "Epoch 10, Loss: 1.1305335760116577\n",
            "Epoch 20, Loss: 0.45783746242523193\n",
            "Epoch 30, Loss: 0.08745983242988586\n",
            "Epoch 40, Loss: 0.01846112310886383\n",
            "Epoch 50, Loss: 0.0027366559952497482\n",
            "Epoch 60, Loss: 0.0006068044458515942\n",
            "Epoch 70, Loss: 0.0019606370478868484\n",
            "Epoch 80, Loss: 0.0006605358212254941\n",
            "Epoch 90, Loss: 0.0007238892139866948\n",
            "Epoch 100, Loss: 0.0005809016874991357\n",
            "Epoch 110, Loss: 8.955871453508735e-05\n",
            "Epoch 120, Loss: 0.0002976180985569954\n",
            "Epoch 130, Loss: 0.00014285063662100583\n",
            "Epoch 140, Loss: 0.00021204205404501408\n",
            "Epoch 150, Loss: 0.0005727570387534797\n",
            "Epoch 160, Loss: 0.0001968852011486888\n",
            "Epoch 170, Loss: 0.00038805505027994514\n",
            "KarateClub - Accuracy: 0.7273, F1 Score: 0.6423, NMI: 0.5859, ARI: 0.3271, Modularity: 0.3574\n",
            "Epoch 0, Loss: 1.9673899412155151\n",
            "Epoch 10, Loss: 1.8166580200195312\n",
            "Epoch 20, Loss: 1.6866652965545654\n",
            "Epoch 30, Loss: 1.3854844570159912\n",
            "Epoch 40, Loss: 1.1671066284179688\n",
            "Epoch 50, Loss: 0.9804763197898865\n",
            "Epoch 60, Loss: 0.8315607905387878\n",
            "Epoch 70, Loss: 0.6890104413032532\n",
            "Epoch 80, Loss: 0.5585770010948181\n",
            "Epoch 90, Loss: 0.43567702174186707\n",
            "Epoch 100, Loss: 0.3473036289215088\n",
            "Epoch 110, Loss: 0.28961512446403503\n",
            "Epoch 120, Loss: 0.23553849756717682\n",
            "Epoch 130, Loss: 0.18444442749023438\n",
            "Epoch 140, Loss: 0.14781469106674194\n",
            "Epoch 150, Loss: 0.11098922789096832\n",
            "Epoch 160, Loss: 0.09549624472856522\n",
            "Epoch 170, Loss: 0.08095227181911469\n",
            "Cora - Accuracy: 0.6494, F1 Score: 0.6123, NMI: 0.4125, ARI: 0.4554, Modularity: 0.4826\n",
            "Epoch 0, Loss: 1.803918480873108\n",
            "Epoch 10, Loss: 1.742179036140442\n",
            "Epoch 20, Loss: 1.5794978141784668\n",
            "Epoch 30, Loss: 1.2152159214019775\n",
            "Epoch 40, Loss: 0.9813131093978882\n",
            "Epoch 50, Loss: 0.781453013420105\n",
            "Epoch 60, Loss: 0.5570586323738098\n",
            "Epoch 70, Loss: 0.3427322804927826\n",
            "Epoch 80, Loss: 0.20859290659427643\n",
            "Epoch 90, Loss: 0.147762730717659\n",
            "Epoch 100, Loss: 0.11708943545818329\n",
            "Epoch 110, Loss: 0.09890304505825043\n",
            "Epoch 120, Loss: 0.08827389031648636\n",
            "Epoch 130, Loss: 0.08309154212474823\n",
            "Epoch 140, Loss: 0.06820882111787796\n",
            "Epoch 150, Loss: 0.05815334618091583\n",
            "Epoch 160, Loss: 0.06195446476340294\n",
            "Epoch 170, Loss: 0.052872397005558014\n",
            "Citeseer - Accuracy: 0.6096, F1 Score: 0.5797, NMI: 0.3264, ARI: 0.3235, Modularity: 0.5556\n",
            "Epoch 0, Loss: 1.377243161201477\n",
            "Epoch 10, Loss: 1.3499815464019775\n",
            "Epoch 20, Loss: 1.217771053314209\n",
            "Epoch 30, Loss: 1.008187174797058\n",
            "Epoch 40, Loss: 0.8116148710250854\n",
            "Epoch 50, Loss: 0.6851392388343811\n",
            "Epoch 60, Loss: 0.5938010811805725\n",
            "Epoch 70, Loss: 0.5238743424415588\n",
            "Epoch 80, Loss: 0.4648137092590332\n",
            "Epoch 90, Loss: 0.44629454612731934\n",
            "Epoch 100, Loss: 0.42369934916496277\n",
            "Epoch 110, Loss: 0.4069271981716156\n",
            "Epoch 120, Loss: 0.42777201533317566\n",
            "Epoch 130, Loss: 0.3988029658794403\n",
            "Epoch 140, Loss: 0.3843171000480652\n",
            "Epoch 150, Loss: 0.3790839910507202\n",
            "Epoch 160, Loss: 0.3779887855052948\n",
            "Epoch 170, Loss: 0.3747671842575073\n",
            "FacebookPagePage - Accuracy: 0.8744, F1 Score: 0.8640, NMI: 0.6380, ARI: 0.7021, Modularity: 0.5089\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_add_pool\n",
        "from torch_geometric.datasets import KarateClub, Planetoid, FacebookPagePage\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import normalized_mutual_info_score, f1_score, accuracy_score, adjusted_rand_score\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "import numpy as np\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.conv = GCNConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "class RNNLayer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(RNNLayer, self).__init__()\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, (h_n, c_n) = self.rnn(x)\n",
        "        return x, (h_n, c_n)\n",
        "\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.attention = nn.Linear(in_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        weights = F.softmax(self.attention(x), dim=1)\n",
        "        return torch.sum(weights * x, dim=1)\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, gcn_input_dim, gcn_output_dim, rnn_input_dim, rnn_hidden_dim, rnn_num_layers, num_classes):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.gcn = GCNLayer(gcn_input_dim, gcn_output_dim)\n",
        "        self.rnn = RNNLayer(rnn_input_dim, rnn_hidden_dim, rnn_num_layers)\n",
        "        self.attention = AttentionLayer(rnn_hidden_dim)\n",
        "        self.fc = nn.Linear(rnn_hidden_dim, num_classes)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # GCN forward\n",
        "        x = self.gcn(x, edge_index)\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        # RNN forward\n",
        "        x, (h_n, c_n) = self.rnn(x)\n",
        "\n",
        "        # Attention Layer\n",
        "        x = self.attention(x)\n",
        "\n",
        "\n",
        "        x = self.fc(self.dropout(x))\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "def train(model, data, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def test(model, data):\n",
        "    model.eval()\n",
        "    logits, accs = model(data), []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "        preds = logits.max(1)[1].cpu().numpy()\n",
        "        labels = data.y.cpu().numpy()\n",
        "\n",
        "\n",
        "    accuracy = accuracy_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()])\n",
        "\n",
        "\n",
        "    f1 = f1_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()], average='macro')\n",
        "\n",
        "\n",
        "    nmi = normalized_mutual_info_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()])\n",
        "\n",
        "\n",
        "    ari = adjusted_rand_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()])\n",
        "\n",
        "\n",
        "    G = to_networkx(data)\n",
        "    communities = {i: preds[i] for i in range(len(preds))}\n",
        "    community_list = [[] for _ in range(data.num_classes)]\n",
        "    for node, community in communities.items():\n",
        "        community_list[community].append(node)\n",
        "    modularity = nx.algorithms.community.modularity(G, community_list)\n",
        "\n",
        "    return accuracy, f1, nmi, ari, modularity\n",
        "\n",
        "def load_data(dataset_name, label_rate):\n",
        "    if dataset_name == 'KarateClub':\n",
        "        data = KarateClub(transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "    elif dataset_name == 'FacebookPagePage':\n",
        "        data = FacebookPagePage(root='/tmp/FacebookPagePage', transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "    else:\n",
        "        data = Planetoid(root=f'/tmp/{dataset_name}', name=dataset_name, transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "\n",
        "\n",
        "    num_nodes = data.y.size(0)\n",
        "    indices = np.random.permutation(num_nodes)\n",
        "    train_size = int(num_nodes * label_rate)\n",
        "    val_size = int(num_nodes * 0.2)\n",
        "    test_size = num_nodes - train_size - val_size\n",
        "\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "    train_mask[indices[:train_size]] = True\n",
        "    val_mask[indices[train_size:train_size + val_size]] = True\n",
        "    test_mask[indices[train_size + val_size:]] = True\n",
        "\n",
        "    data.train_mask = train_mask\n",
        "    data.val_mask = val_mask\n",
        "    data.test_mask = test_mask\n",
        "\n",
        "    return data\n",
        "\n",
        "label_rates = [0.5]\n",
        "\n",
        "datasets = ['KarateClub', 'Cora', 'Citeseer', 'FacebookPagePage']\n",
        "for label_rate in label_rates:\n",
        "    print(f'Label Rate: {label_rate*100}%')\n",
        "    for dataset_name in datasets:\n",
        "        data = load_data(dataset_name, label_rate)\n",
        "\n",
        "\n",
        "        model = HybridModel(gcn_input_dim=data.num_node_features, gcn_output_dim=32,\n",
        "                            rnn_input_dim=32, rnn_hidden_dim=64, rnn_num_layers=2, num_classes=data.num_classes)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "        for epoch in range(180):\n",
        "            loss = train(model, data, optimizer, criterion)\n",
        "            if epoch % 10 == 0:\n",
        "                print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "\n",
        "        accuracy, f1, nmi, ari, modularity = evaluate(model, data)\n",
        "        print(f'{dataset_name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, NMI: {nmi:.4f}, ARI: {ari:.4f}, Modularity: {modularity:.4f}')\n",
        "    print('-' * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9763e8a9",
      "metadata": {
        "id": "9763e8a9",
        "outputId": "e6693147-0efd-4033-ce9e-f23898a49279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Rate: 100.0%\n",
            "Epoch 0, Loss: 1.3896249532699585\n",
            "Epoch 10, Loss: 1.1538077592849731\n",
            "Epoch 20, Loss: 0.5244362354278564\n",
            "Epoch 30, Loss: 0.15389834344387054\n",
            "Epoch 40, Loss: 0.025691548362374306\n",
            "Epoch 50, Loss: 0.002779630245640874\n",
            "Epoch 60, Loss: 0.001739880652166903\n",
            "Epoch 70, Loss: 0.0002869184536393732\n",
            "Epoch 80, Loss: 0.0023265762720257044\n",
            "Epoch 90, Loss: 0.0005375660257413983\n",
            "Epoch 100, Loss: 0.0009038196294568479\n",
            "Epoch 110, Loss: 0.00044713864917866886\n",
            "Epoch 120, Loss: 0.0002655461139511317\n",
            "Epoch 130, Loss: 0.0006343198474496603\n",
            "Epoch 140, Loss: 0.0003869888896588236\n",
            "Epoch 150, Loss: 0.0003263674443587661\n",
            "Epoch 160, Loss: 0.00016747225890867412\n",
            "Epoch 170, Loss: 0.00014289995306171477\n",
            "Epoch 180, Loss: 0.000239127068198286\n",
            "Epoch 190, Loss: 0.0005173737881705165\n",
            "KarateClub - Accuracy: 0.7500, F1 Score: 0.6000, NMI: 0.7020, ARI: 0.3333, Modularity: 0.3638\n",
            "Epoch 0, Loss: 1.9273933172225952\n",
            "Epoch 10, Loss: 1.8261311054229736\n",
            "Epoch 20, Loss: 1.675776720046997\n",
            "Epoch 30, Loss: 1.3031933307647705\n",
            "Epoch 40, Loss: 1.0877151489257812\n",
            "Epoch 50, Loss: 0.7711735367774963\n",
            "Epoch 60, Loss: 0.5332819223403931\n",
            "Epoch 70, Loss: 0.3723597228527069\n",
            "Epoch 80, Loss: 0.2715924084186554\n",
            "Epoch 90, Loss: 0.18607011437416077\n",
            "Epoch 100, Loss: 0.11966049671173096\n",
            "Epoch 110, Loss: 0.08632911741733551\n",
            "Epoch 120, Loss: 0.06824944913387299\n",
            "Epoch 130, Loss: 0.056560564786195755\n",
            "Epoch 140, Loss: 0.042042043060064316\n",
            "Epoch 150, Loss: 0.03935550898313522\n",
            "Epoch 160, Loss: 0.031537674367427826\n",
            "Epoch 170, Loss: 0.030768798664212227\n",
            "Epoch 180, Loss: 0.022031225264072418\n",
            "Epoch 190, Loss: 0.019852761179208755\n",
            "Cora - Accuracy: 0.7574, F1 Score: 0.7379, NMI: 0.5654, ARI: 0.5405, Modularity: 0.6262\n",
            "Epoch 0, Loss: 1.7904572486877441\n",
            "Epoch 10, Loss: 1.750225305557251\n",
            "Epoch 20, Loss: 1.6486825942993164\n",
            "Epoch 30, Loss: 1.1885772943496704\n",
            "Epoch 40, Loss: 0.7471729516983032\n",
            "Epoch 50, Loss: 0.5048540234565735\n",
            "Epoch 60, Loss: 0.33159342408180237\n",
            "Epoch 70, Loss: 0.22408267855644226\n",
            "Epoch 80, Loss: 0.13906414806842804\n",
            "Epoch 90, Loss: 0.10829933732748032\n",
            "Epoch 100, Loss: 0.0847923755645752\n",
            "Epoch 110, Loss: 0.07668948918581009\n",
            "Epoch 120, Loss: 0.06464846432209015\n",
            "Epoch 130, Loss: 0.05798058956861496\n",
            "Epoch 140, Loss: 0.059623003005981445\n",
            "Epoch 150, Loss: 0.05919673293828964\n",
            "Epoch 160, Loss: 0.0567338690161705\n",
            "Epoch 170, Loss: 0.059170912951231\n",
            "Epoch 180, Loss: 0.05341806635260582\n",
            "Epoch 190, Loss: 0.05122711509466171\n",
            "Citeseer - Accuracy: 0.6856, F1 Score: 0.6401, NMI: 0.4018, ARI: 0.4318, Modularity: 0.5698\n",
            "Epoch 0, Loss: 1.3829419612884521\n",
            "Epoch 10, Loss: 1.3527071475982666\n",
            "Epoch 20, Loss: 1.3056812286376953\n",
            "Epoch 30, Loss: 0.9288308024406433\n",
            "Epoch 40, Loss: 0.6819844245910645\n",
            "Epoch 50, Loss: 0.5405571460723877\n",
            "Epoch 60, Loss: 0.4910467565059662\n",
            "Epoch 70, Loss: 0.46928277611732483\n",
            "Epoch 80, Loss: 0.4507290720939636\n",
            "Epoch 90, Loss: 0.43539369106292725\n",
            "Epoch 100, Loss: 0.42946845293045044\n",
            "Epoch 110, Loss: 0.4223775565624237\n",
            "Epoch 120, Loss: 0.41599810123443604\n",
            "Epoch 130, Loss: 0.41344699263572693\n",
            "Epoch 140, Loss: 0.4090292155742645\n",
            "Epoch 150, Loss: 0.4094538688659668\n",
            "Epoch 160, Loss: 0.40944361686706543\n",
            "Epoch 170, Loss: 0.4054056406021118\n",
            "Epoch 180, Loss: 0.40223804116249084\n",
            "Epoch 190, Loss: 0.40070149302482605\n",
            "FacebookPagePage - Accuracy: 0.8603, F1 Score: 0.8472, NMI: 0.6125, ARI: 0.6770, Modularity: 0.5088\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_add_pool\n",
        "from torch_geometric.datasets import KarateClub, Planetoid, FacebookPagePage\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import normalized_mutual_info_score, f1_score, accuracy_score, adjusted_rand_score\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "import numpy as np\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.conv = GCNConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "class RNNLayer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(RNNLayer, self).__init__()\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, (h_n, c_n) = self.rnn(x)\n",
        "        return x, (h_n, c_n)\n",
        "\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.attention = nn.Linear(in_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        weights = F.softmax(self.attention(x), dim=1)\n",
        "        return torch.sum(weights * x, dim=1)\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, gcn_input_dim, gcn_output_dim, rnn_input_dim, rnn_hidden_dim, rnn_num_layers, num_classes):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.gcn = GCNLayer(gcn_input_dim, gcn_output_dim)\n",
        "        self.rnn = RNNLayer(rnn_input_dim, rnn_hidden_dim, rnn_num_layers)\n",
        "        self.attention = AttentionLayer(rnn_hidden_dim)\n",
        "        self.fc = nn.Linear(rnn_hidden_dim, num_classes)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.gcn(x, edge_index)\n",
        "        x = x.unsqueeze(1)\n",
        "        x, (h_n, c_n) = self.rnn(x)\n",
        "        x = self.attention(x)\n",
        "        x = self.fc(self.dropout(x))\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "def train(model, data, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def test(model, data):\n",
        "    model.eval()\n",
        "    logits, accs = model(data), []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "        preds = logits.max(1)[1].cpu().numpy()\n",
        "        labels = data.y.cpu().numpy()\n",
        "\n",
        "    accuracy = accuracy_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()]) if torch.count_nonzero(data.test_mask) > 0 else float('nan')\n",
        "    f1 = f1_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()], average='macro') if torch.count_nonzero(data.test_mask) > 0 else float('nan')\n",
        "    nmi = normalized_mutual_info_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()]) if torch.count_nonzero(data.test_mask) > 0 else float('nan')\n",
        "    ari = adjusted_rand_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()]) if torch.count_nonzero(data.test_mask) > 0 else float('nan')\n",
        "\n",
        "    if torch.count_nonzero(data.test_mask) > 0:\n",
        "        G = to_networkx(data)\n",
        "        communities = {i: preds[i] for i in range(len(preds))}\n",
        "        community_list = [[] for _ in range(data.num_classes)]\n",
        "        for node, community in communities.items():\n",
        "            community_list[community].append(node)\n",
        "        modularity = nx.algorithms.community.modularity(G, community_list)\n",
        "    else:\n",
        "        modularity = float('nan')\n",
        "\n",
        "    return accuracy, f1, nmi, ari, modularity\n",
        "\n",
        "def load_data(dataset_name, label_rate):\n",
        "    if dataset_name == 'KarateClub':\n",
        "        data = KarateClub(transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "    elif dataset_name == 'FacebookPagePage':\n",
        "        data = FacebookPagePage(root='/tmp/FacebookPagePage', transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "    else:\n",
        "        data = Planetoid(root=f'/tmp/{dataset_name}', name=dataset_name, transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "\n",
        "    num_nodes = data.y.size(0)\n",
        "    indices = np.random.permutation(num_nodes)\n",
        "    train_size = int(num_nodes * label_rate * 0.8)\n",
        "    val_size = int(num_nodes * 0.1)\n",
        "    test_size = num_nodes - train_size - val_size\n",
        "\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "    train_mask[indices[:train_size]] = True\n",
        "    val_mask[indices[train_size:train_size + val_size]] = True\n",
        "    test_mask[indices[train_size + val_size:]] = True\n",
        "\n",
        "    data.train_mask = train_mask\n",
        "    data.val_mask = val_mask\n",
        "    data.test_mask = test_mask\n",
        "\n",
        "    return data\n",
        "\n",
        "label_rates = [1.0]\n",
        "datasets = ['KarateClub', 'Cora', 'Citeseer', 'FacebookPagePage']\n",
        "\n",
        "for label_rate in label_rates:\n",
        "    print(f'Label Rate: {label_rate*100}%')\n",
        "    for dataset_name in datasets:\n",
        "        data = load_data(dataset_name, label_rate)\n",
        "\n",
        "        model = HybridModel(gcn_input_dim=data.num_node_features, gcn_output_dim=32,\n",
        "                            rnn_input_dim=32, rnn_hidden_dim=64, rnn_num_layers=2, num_classes=data.num_classes)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(200):\n",
        "            loss = train(model, data, optimizer, criterion)\n",
        "            if epoch % 10 == 0:\n",
        "                print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "        accuracy, f1, nmi, ari, modularity = evaluate(model, data)\n",
        "        print(f'{dataset_name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, NMI: {nmi:.4f}, ARI: {ari:.4f}, Modularity: {modularity:.4f}')\n",
        "    print('-' * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ace8b295",
      "metadata": {
        "id": "ace8b295",
        "outputId": "761a8e5a-a9a4-4429-8564-e30952e3d76d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Rate: 100.0%\n",
            "Epoch 0, Loss: 1.3688477277755737\n",
            "Epoch 10, Loss: 1.150694489479065\n",
            "Epoch 20, Loss: 0.5094664096832275\n",
            "Epoch 30, Loss: 0.2290314882993698\n",
            "Epoch 40, Loss: 0.044556599110364914\n",
            "Epoch 50, Loss: 0.009075943380594254\n",
            "Epoch 60, Loss: 0.0014017247594892979\n",
            "Epoch 70, Loss: 0.0005230701644904912\n",
            "Epoch 80, Loss: 0.0003734665224328637\n",
            "Epoch 90, Loss: 0.0007931272266432643\n",
            "Epoch 100, Loss: 0.0006164037040434778\n",
            "Epoch 110, Loss: 0.00012113459524698555\n",
            "Epoch 120, Loss: 0.00046678713988512754\n",
            "Epoch 130, Loss: 0.0005480805994011462\n",
            "Epoch 140, Loss: 0.00029284681659191847\n",
            "Epoch 150, Loss: 0.00027710673748515546\n",
            "Epoch 160, Loss: 0.0004492539737839252\n",
            "Epoch 170, Loss: 0.00030655748560093343\n",
            "Epoch 180, Loss: 0.0003795860684476793\n",
            "Epoch 190, Loss: 0.00014023740368429571\n",
            "Epoch 200, Loss: 0.00024865646264515817\n",
            "Epoch 210, Loss: 0.0003798681136686355\n",
            "Epoch 220, Loss: 0.00016028116806410253\n",
            "Epoch 230, Loss: 0.00020101285190321505\n",
            "Epoch 240, Loss: 0.0005142365698702633\n",
            "Epoch 250, Loss: 0.0003203097148798406\n",
            "Epoch 260, Loss: 6.397680408554152e-05\n",
            "Epoch 270, Loss: 0.00018685980467125773\n",
            "Epoch 280, Loss: 0.00010254597145831212\n",
            "Epoch 290, Loss: 0.0007690363563597202\n",
            "Epoch 300, Loss: 0.00039829540764912963\n",
            "KarateClub - Accuracy: 1.0000, F1 Score: 1.0000, NMI: 1.0000, ARI: 1.0000, Modularity: 0.4156\n",
            "Epoch 0, Loss: 1.9532638788223267\n",
            "Epoch 10, Loss: 1.8280751705169678\n",
            "Epoch 20, Loss: 1.7037570476531982\n",
            "Epoch 30, Loss: 1.3463548421859741\n",
            "Epoch 40, Loss: 1.1991677284240723\n",
            "Epoch 50, Loss: 0.9680212140083313\n",
            "Epoch 60, Loss: 0.7098048329353333\n",
            "Epoch 70, Loss: 0.49670347571372986\n",
            "Epoch 80, Loss: 0.37895482778549194\n",
            "Epoch 90, Loss: 0.2883407771587372\n",
            "Epoch 100, Loss: 0.22520692646503448\n",
            "Epoch 110, Loss: 0.1481221318244934\n",
            "Epoch 120, Loss: 0.0857151597738266\n",
            "Epoch 130, Loss: 0.06097083166241646\n",
            "Epoch 140, Loss: 0.04311276599764824\n",
            "Epoch 150, Loss: 0.03533875569701195\n",
            "Epoch 160, Loss: 0.03061201609671116\n",
            "Epoch 170, Loss: 0.02559977024793625\n",
            "Epoch 180, Loss: 0.022928515449166298\n",
            "Epoch 190, Loss: 0.026688970625400543\n",
            "Epoch 200, Loss: 0.021595988422632217\n",
            "Epoch 210, Loss: 0.019130242988467216\n",
            "Epoch 220, Loss: 0.020296359434723854\n",
            "Epoch 230, Loss: 0.01675133779644966\n",
            "Epoch 240, Loss: 0.018073339015245438\n",
            "Epoch 250, Loss: 0.01700083538889885\n",
            "Epoch 260, Loss: 0.01629694737493992\n",
            "Epoch 270, Loss: 0.013970036059617996\n",
            "Epoch 280, Loss: 0.013403767719864845\n",
            "Epoch 290, Loss: 0.014366189949214458\n",
            "Epoch 300, Loss: 0.013796381652355194\n",
            "Cora - Accuracy: 0.7941, F1 Score: 0.7626, NMI: 0.6261, ARI: 0.6449, Modularity: 0.6366\n",
            "Epoch 0, Loss: 1.7859724760055542\n",
            "Epoch 10, Loss: 1.7509649991989136\n",
            "Epoch 20, Loss: 1.640246868133545\n",
            "Epoch 30, Loss: 1.2710597515106201\n",
            "Epoch 40, Loss: 0.8780450820922852\n",
            "Epoch 50, Loss: 0.6006680727005005\n",
            "Epoch 60, Loss: 0.44694286584854126\n",
            "Epoch 70, Loss: 0.3254028856754303\n",
            "Epoch 80, Loss: 0.2306974083185196\n",
            "Epoch 90, Loss: 0.1677684634923935\n",
            "Epoch 100, Loss: 0.13380439579486847\n",
            "Epoch 110, Loss: 0.12626731395721436\n",
            "Epoch 120, Loss: 0.10662949830293655\n",
            "Epoch 130, Loss: 0.09740810841321945\n",
            "Epoch 140, Loss: 0.08312731981277466\n",
            "Epoch 150, Loss: 0.08963578939437866\n",
            "Epoch 160, Loss: 0.08277356624603271\n",
            "Epoch 170, Loss: 0.07396821677684784\n",
            "Epoch 180, Loss: 0.07578692585229874\n",
            "Epoch 190, Loss: 0.07629632949829102\n",
            "Epoch 200, Loss: 0.0730140209197998\n",
            "Epoch 210, Loss: 0.0726105347275734\n",
            "Epoch 220, Loss: 0.06511291861534119\n",
            "Epoch 230, Loss: 0.06457087397575378\n",
            "Epoch 240, Loss: 0.06599456071853638\n",
            "Epoch 250, Loss: 0.05745923891663551\n",
            "Epoch 260, Loss: 0.059778276830911636\n",
            "Epoch 270, Loss: 0.061563581228256226\n",
            "Epoch 280, Loss: 0.061754487454891205\n",
            "Epoch 290, Loss: 0.05699080228805542\n",
            "Epoch 300, Loss: 0.054483477026224136\n",
            "Citeseer - Accuracy: 0.7515, F1 Score: 0.7228, NMI: 0.5032, ARI: 0.5099, Modularity: 0.5721\n",
            "Epoch 0, Loss: 1.383305549621582\n",
            "Epoch 10, Loss: 1.3513514995574951\n",
            "Epoch 20, Loss: 1.3095623254776\n",
            "Epoch 30, Loss: 0.9944893717765808\n",
            "Epoch 40, Loss: 0.7399160861968994\n",
            "Epoch 50, Loss: 0.5924768447875977\n",
            "Epoch 60, Loss: 0.5084837675094604\n",
            "Epoch 70, Loss: 0.47193458676338196\n",
            "Epoch 80, Loss: 0.43603479862213135\n",
            "Epoch 90, Loss: 0.42676809430122375\n",
            "Epoch 100, Loss: 0.4167254567146301\n",
            "Epoch 110, Loss: 0.40743932127952576\n",
            "Epoch 120, Loss: 0.40234366059303284\n",
            "Epoch 130, Loss: 0.4144621193408966\n",
            "Epoch 140, Loss: 0.400422066450119\n",
            "Epoch 150, Loss: 0.3902122974395752\n",
            "Epoch 160, Loss: 0.3891490697860718\n",
            "Epoch 170, Loss: 0.3834393322467804\n",
            "Epoch 180, Loss: 0.3815072476863861\n",
            "Epoch 190, Loss: 0.3778970241546631\n",
            "Epoch 200, Loss: 0.3774036765098572\n",
            "Epoch 210, Loss: 0.3716038763523102\n",
            "Epoch 220, Loss: 0.3715316951274872\n",
            "Epoch 230, Loss: 0.3673482835292816\n",
            "Epoch 240, Loss: 0.36512693762779236\n",
            "Epoch 250, Loss: 0.366798996925354\n",
            "Epoch 260, Loss: 0.3624020516872406\n",
            "Epoch 270, Loss: 0.3612504005432129\n",
            "Epoch 280, Loss: 0.3553008735179901\n",
            "Epoch 290, Loss: 0.3543856143951416\n",
            "Epoch 300, Loss: 0.3532296419143677\n",
            "FacebookPagePage - Accuracy: 0.8678, F1 Score: 0.8594, NMI: 0.6293, ARI: 0.6874, Modularity: 0.5132\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, global_add_pool\n",
        "from torch_geometric.datasets import KarateClub, Planetoid, FacebookPagePage\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import normalized_mutual_info_score, f1_score, accuracy_score, adjusted_rand_score\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "import numpy as np\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.conv = GCNConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "class RNNLayer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(RNNLayer, self).__init__()\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, (h_n, c_n) = self.rnn(x)\n",
        "        return x, (h_n, c_n)\n",
        "\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.attention = nn.Linear(in_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        weights = F.softmax(self.attention(x), dim=1)\n",
        "        return torch.sum(weights * x, dim=1)\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, gcn_input_dim, gcn_output_dim, rnn_input_dim, rnn_hidden_dim, rnn_num_layers, num_classes):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.gcn = GCNLayer(gcn_input_dim, gcn_output_dim)\n",
        "        self.rnn = RNNLayer(rnn_input_dim, rnn_hidden_dim, rnn_num_layers)\n",
        "        self.attention = AttentionLayer(rnn_hidden_dim)\n",
        "        self.fc = nn.Linear(rnn_hidden_dim, num_classes)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.gcn(x, edge_index)\n",
        "        x = x.unsqueeze(1)\n",
        "        x, (h_n, c_n) = self.rnn(x)\n",
        "        x = self.attention(x)\n",
        "        x = self.fc(self.dropout(x))\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "def train(model, data, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def test(model, data):\n",
        "    model.eval()\n",
        "    logits, accs = model(data), []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "        preds = logits.max(1)[1].cpu().numpy()\n",
        "        labels = data.y.cpu().numpy()\n",
        "\n",
        "    accuracy = accuracy_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()]) if torch.count_nonzero(data.test_mask) > 0 else float('nan')\n",
        "    f1 = f1_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()], average='macro') if torch.count_nonzero(data.test_mask) > 0 else float('nan')\n",
        "    nmi = normalized_mutual_info_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()]) if torch.count_nonzero(data.test_mask) > 0 else float('nan')\n",
        "    ari = adjusted_rand_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()]) if torch.count_nonzero(data.test_mask) > 0 else float('nan')\n",
        "\n",
        "    if torch.count_nonzero(data.test_mask) > 0:\n",
        "        G = to_networkx(data)\n",
        "        communities = {i: preds[i] for i in range(len(preds))}\n",
        "        community_list = [[] for _ in range(data.num_classes)]\n",
        "        for node, community in communities.items():\n",
        "            community_list[community].append(node)\n",
        "        modularity = nx.algorithms.community.modularity(G, community_list)\n",
        "    else:\n",
        "        modularity = float('nan')\n",
        "\n",
        "    return accuracy, f1, nmi, ari, modularity\n",
        "\n",
        "def load_data(dataset_name, label_rate):\n",
        "    if dataset_name == 'KarateClub':\n",
        "        data = KarateClub(transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "    elif dataset_name == 'FacebookPagePage':\n",
        "        data = FacebookPagePage(root='/tmp/FacebookPagePage', transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "    else:\n",
        "        data = Planetoid(root=f'/tmp/{dataset_name}', name=dataset_name, transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "\n",
        "    num_nodes = data.y.size(0)\n",
        "    indices = np.random.permutation(num_nodes)\n",
        "    train_size = int(num_nodes * label_rate * 0.8)\n",
        "    val_size = int(num_nodes * 0.1)\n",
        "    test_size = num_nodes - train_size - val_size\n",
        "\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "    train_mask[indices[:train_size]] = True\n",
        "    val_mask[indices[train_size:train_size + val_size]] = True\n",
        "    test_mask[indices[train_size + val_size:]] = True\n",
        "\n",
        "    data.train_mask = train_mask\n",
        "    data.val_mask = val_mask\n",
        "    data.test_mask = test_mask\n",
        "\n",
        "    return data\n",
        "\n",
        "label_rates = [1.0]\n",
        "datasets = ['KarateClub', 'Cora', 'Citeseer', 'FacebookPagePage']\n",
        "\n",
        "for label_rate in label_rates:\n",
        "    print(f'Label Rate: {label_rate*100}%')\n",
        "    for dataset_name in datasets:\n",
        "        data = load_data(dataset_name, label_rate)\n",
        "\n",
        "        model = HybridModel(gcn_input_dim=data.num_node_features, gcn_output_dim=32,\n",
        "                            rnn_input_dim=32, rnn_hidden_dim=64, rnn_num_layers=2, num_classes=data.num_classes)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(310):\n",
        "            loss = train(model, data, optimizer, criterion)\n",
        "            if epoch % 10 == 0:\n",
        "                print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "        accuracy, f1, nmi, ari, modularity = evaluate(model, data)\n",
        "        print(f'{dataset_name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, NMI: {nmi:.4f}, ARI: {ari:.4f}, Modularity: {modularity:.4f}')\n",
        "    print('-' * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b07a62b",
      "metadata": {
        "id": "3b07a62b",
        "outputId": "821431e8-17d1-4cbe-987b-189589ed59e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Rate: 100.0%\n",
            "Epoch 0, Loss: 1.3783901929855347\n",
            "Epoch 10, Loss: 1.2081594467163086\n",
            "Epoch 20, Loss: 0.6487535834312439\n",
            "Epoch 30, Loss: 0.12527935206890106\n",
            "Epoch 40, Loss: 0.0029193072114139795\n",
            "Epoch 50, Loss: 0.002836272120475769\n",
            "Epoch 60, Loss: 0.0005893099587410688\n",
            "Epoch 70, Loss: 0.0006468232022598386\n",
            "Epoch 80, Loss: 0.0005300342454575002\n",
            "Epoch 90, Loss: 0.0005520393024198711\n",
            "Epoch 100, Loss: 0.00020218607096467167\n",
            "Epoch 110, Loss: 0.00019377554417587817\n",
            "Epoch 120, Loss: 0.0001147677467088215\n",
            "Epoch 130, Loss: 0.0002388063003309071\n",
            "Epoch 140, Loss: 6.855453102616593e-05\n",
            "Epoch 150, Loss: 0.0002886205620598048\n",
            "KarateClub - Accuracy: 0.7500, F1 Score: 0.6000, NMI: 0.7020, ARI: 0.3333, Modularity: 0.3410\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.datasets import KarateClub, Planetoid, FacebookPagePage\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from sklearn.metrics import normalized_mutual_info_score, f1_score, accuracy_score, adjusted_rand_score\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "import numpy as np\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.conv = GCNConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "class RNNLayer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(RNNLayer, self).__init__()\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, (h_n, c_n) = self.rnn(x)\n",
        "        return x, (h_n, c_n)\n",
        "\n",
        "class AttentionLayer(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(AttentionLayer, self).__init__()\n",
        "        self.attention = nn.Linear(in_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        weights = F.softmax(self.attention(x), dim=1)\n",
        "        return torch.sum(weights * x, dim=1)\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, gcn_input_dim, gcn_output_dim, rnn_input_dim, rnn_hidden_dim, rnn_num_layers, num_classes):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.gcn = GCNLayer(gcn_input_dim, gcn_output_dim)\n",
        "        self.rnn = RNNLayer(rnn_input_dim, rnn_hidden_dim, rnn_num_layers)\n",
        "        self.attention = AttentionLayer(rnn_hidden_dim)\n",
        "        self.fc = nn.Linear(rnn_hidden_dim, num_classes)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.gcn(x, edge_index)\n",
        "        x = x.unsqueeze(1)\n",
        "        x, (h_n, c_n) = self.rnn(x)\n",
        "        x = self.attention(x)\n",
        "        x = self.fc(self.dropout(x))\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "def train(model, data, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "        preds = logits.max(1)[1].cpu().numpy()\n",
        "        labels = data.y.cpu().numpy()\n",
        "\n",
        "        accuracy = accuracy_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()]) if torch.count_nonzero(data.test_mask) > 0 else float('nan')\n",
        "        f1 = f1_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()], average='macro') if torch.count_nonzero(data.test_mask) > 0 else float('nan')\n",
        "        nmi = normalized_mutual_info_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()]) if torch.count_nonzero(data.test_mask) > 0 else float('nan')\n",
        "        ari = adjusted_rand_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()]) if torch.count_nonzero(data.test_mask) > 0 else float('nan')\n",
        "\n",
        "        if torch.count_nonzero(data.test_mask) > 0:\n",
        "            G = to_networkx(data)\n",
        "            communities = {i: preds[i] for i in range(len(preds))}\n",
        "            community_list = [[] for _ in range(data.num_classes)]\n",
        "            for node, community in communities.items():\n",
        "                community_list[community].append(node)\n",
        "            modularity = nx.algorithms.community.modularity(G, community_list)\n",
        "        else:\n",
        "            modularity = float('nan')\n",
        "\n",
        "        return accuracy, f1, nmi, ari, modularity\n",
        "\n",
        "def load_data(dataset_name, label_rate):\n",
        "    if dataset_name == 'KarateClub':\n",
        "        data = KarateClub(transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "    elif dataset_name == 'FacebookPagePage':\n",
        "        data = FacebookPagePage(root='/tmp/FacebookPagePage', transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "    else:\n",
        "        data = Planetoid(root=f'/tmp/{dataset_name}', name=dataset_name, transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "\n",
        "    num_nodes = data.y.size(0)\n",
        "    indices = np.random.permutation(num_nodes)\n",
        "    train_size = int(num_nodes * label_rate * 0.8)\n",
        "    val_size = int(num_nodes * 0.1)\n",
        "    test_size = num_nodes - train_size - val_size\n",
        "\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "    train_mask[indices[:train_size]] = True\n",
        "    val_mask[indices[train_size:train_size + val_size]] = True\n",
        "    test_mask[indices[train_size + val_size:]] = True\n",
        "\n",
        "    data.train_mask = train_mask\n",
        "    data.val_mask = val_mask\n",
        "    data.test_mask = test_mask\n",
        "\n",
        "    return data\n",
        "\n",
        "label_rates = [1.0]\n",
        "datasets = ['KarateClub']\n",
        "\n",
        "for label_rate in label_rates:\n",
        "    print(f'Label Rate: {label_rate*100}%')\n",
        "    for dataset_name in datasets:\n",
        "        data = load_data(dataset_name, label_rate)\n",
        "\n",
        "        model = HybridModel(gcn_input_dim=data.num_node_features, gcn_output_dim=32,\n",
        "                            rnn_input_dim=32, rnn_hidden_dim=64, rnn_num_layers=2, num_classes=data.num_classes)\n",
        "\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(160):\n",
        "            loss = train(model, data, optimizer, criterion)\n",
        "            if epoch % 10 == 0:\n",
        "                print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "        accuracy, f1, nmi, ari, modularity = evaluate(model, data)\n",
        "        print(f'{dataset_name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, NMI: {nmi:.4f}, ARI: {ari:.4f}, Modularity: {modularity:.4f}')\n",
        "    print('-' * 50)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}