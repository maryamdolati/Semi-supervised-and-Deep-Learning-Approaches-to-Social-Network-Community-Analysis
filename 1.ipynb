{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ccd5c49",
      "metadata": {
        "id": "8ccd5c49",
        "outputId": "3e56cf47-1f90-47f0-f128-863f845453bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 1.4025779962539673\n",
            "Epoch 10, Loss: 1.1635318994522095\n",
            "Epoch 20, Loss: 0.4141424596309662\n",
            "Epoch 30, Loss: 0.0777798444032669\n",
            "Epoch 40, Loss: 0.0005754625890403986\n",
            "Epoch 50, Loss: 0.00011458154767751694\n",
            "Epoch 60, Loss: 8.227933722082525e-05\n",
            "Epoch 70, Loss: 6.816041423007846e-05\n",
            "Epoch 80, Loss: 5.8821278798859566e-05\n",
            "Epoch 90, Loss: 5.13713966938667e-05\n",
            "Epoch 100, Loss: 4.569748853100464e-05\n",
            "Epoch 110, Loss: 4.138837175560184e-05\n",
            "Epoch 120, Loss: 3.809242480201647e-05\n",
            "Epoch 130, Loss: 3.5475917684379965e-05\n",
            "Epoch 140, Loss: 3.331236803205684e-05\n",
            "Epoch 150, Loss: 3.1482581107411534e-05\n",
            "Epoch 160, Loss: 2.9891194571973756e-05\n",
            "Epoch 170, Loss: 2.8496497179730795e-05\n",
            "KarateClub - Accuracy: 0.8750, F1 Score: 0.7000, NMI: 0.9007, Modularity: 0.3898\n",
            "Epoch 0, Loss: 1.9356201887130737\n",
            "Epoch 10, Loss: 1.816191554069519\n",
            "Epoch 20, Loss: 1.6685070991516113\n",
            "Epoch 30, Loss: 1.2845604419708252\n",
            "Epoch 40, Loss: 0.9115021824836731\n",
            "Epoch 50, Loss: 0.5922475457191467\n",
            "Epoch 60, Loss: 0.4152093529701233\n",
            "Epoch 70, Loss: 0.27662327885627747\n",
            "Epoch 80, Loss: 0.1320115029811859\n",
            "Epoch 90, Loss: 0.06296679377555847\n",
            "Epoch 100, Loss: 0.027211403474211693\n",
            "Epoch 110, Loss: 0.015187820419669151\n",
            "Epoch 120, Loss: 0.010359522886574268\n",
            "Epoch 130, Loss: 0.007950208149850368\n",
            "Epoch 140, Loss: 0.006383230909705162\n",
            "Epoch 150, Loss: 0.005354362539947033\n",
            "Epoch 160, Loss: 0.004626106005162001\n",
            "Epoch 170, Loss: 0.004087082110345364\n",
            "Cora - Accuracy: 0.7901, F1 Score: 0.7652, NMI: 0.5870, Modularity: 0.6215\n",
            "Epoch 0, Loss: 1.784572720527649\n",
            "Epoch 10, Loss: 1.7485198974609375\n",
            "Epoch 20, Loss: 1.4454158544540405\n",
            "Epoch 30, Loss: 0.856989324092865\n",
            "Epoch 40, Loss: 0.49585363268852234\n",
            "Epoch 50, Loss: 0.22775320708751678\n",
            "Epoch 60, Loss: 0.09805572032928467\n",
            "Epoch 70, Loss: 0.04678354412317276\n",
            "Epoch 80, Loss: 0.03011721558868885\n",
            "Epoch 90, Loss: 0.025031181052327156\n",
            "Epoch 100, Loss: 0.02237720787525177\n",
            "Epoch 110, Loss: 0.021405167877674103\n",
            "Epoch 120, Loss: 0.020618025213479996\n",
            "Epoch 130, Loss: 0.020227396860718727\n",
            "Epoch 140, Loss: 0.020082764327526093\n",
            "Epoch 150, Loss: 0.019793592393398285\n",
            "Epoch 160, Loss: 0.01985691301524639\n",
            "Epoch 170, Loss: 0.019535807892680168\n",
            "Citeseer - Accuracy: 0.7087, F1 Score: 0.6584, NMI: 0.4255, Modularity: 0.6093\n",
            "Epoch 0, Loss: 1.3703314065933228\n",
            "Epoch 10, Loss: 1.3480061292648315\n",
            "Epoch 20, Loss: 1.17336905002594\n",
            "Epoch 30, Loss: 0.7364533543586731\n",
            "Epoch 40, Loss: 0.6138651967048645\n",
            "Epoch 50, Loss: 0.5250393748283386\n",
            "Epoch 60, Loss: 0.4769798219203949\n",
            "Epoch 70, Loss: 0.4575630724430084\n",
            "Epoch 80, Loss: 0.4386177361011505\n",
            "Epoch 90, Loss: 0.42195257544517517\n",
            "Epoch 100, Loss: 0.41138067841529846\n",
            "Epoch 110, Loss: 0.40494832396507263\n",
            "Epoch 120, Loss: 0.40845561027526855\n",
            "Epoch 130, Loss: 0.3962111473083496\n",
            "Epoch 140, Loss: 0.39437544345855713\n",
            "Epoch 150, Loss: 0.3911292850971222\n",
            "Epoch 160, Loss: 0.39470264315605164\n",
            "Epoch 170, Loss: 0.39011865854263306\n",
            "FacebookPagePage - Accuracy: 0.8505, F1 Score: 0.8381, NMI: 0.5937, Modularity: 0.5094\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.datasets import KarateClub, Planetoid, FacebookPagePage\n",
        "from torch_geometric.transforms import NormalizeFeatures\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.metrics import normalized_mutual_info_score, f1_score, accuracy_score\n",
        "import networkx as nx\n",
        "from torch_geometric.utils import to_networkx\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class GCNLayer(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(GCNLayer, self).__init__()\n",
        "        self.conv = GCNConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "class RNNLayer(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers):\n",
        "        super(RNNLayer, self).__init__()\n",
        "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, (h_n, c_n) = self.rnn(x)\n",
        "        return x, (h_n, c_n)\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, gcn_input_dim, gcn_output_dim, rnn_input_dim, rnn_hidden_dim, rnn_num_layers, num_classes):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.gcn = GCNLayer(gcn_input_dim, gcn_output_dim)\n",
        "        self.rnn = RNNLayer(rnn_input_dim, rnn_hidden_dim, rnn_num_layers)\n",
        "        self.fc = nn.Linear(rnn_hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # GCN forward\n",
        "        x = self.gcn(x, edge_index)\n",
        "        x = x.unsqueeze(1)\n",
        "\n",
        "        # RNN forward\n",
        "        x, (h_n, c_n) = self.rnn(x)\n",
        "\n",
        "\n",
        "        x = self.fc(x[:, -1, :])\n",
        "        return F.log_softmax(x, dim=-1)\n",
        "\n",
        "\n",
        "def train(model, data, optimizer, criterion):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    out = model(data)\n",
        "    loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "def test(model, data):\n",
        "    model.eval()\n",
        "    logits, accs = model(data), []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        pred = logits[mask].max(1)[1]\n",
        "        acc = pred.eq(data.y[mask]).sum().item() / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs\n",
        "\n",
        "def evaluate(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "        preds = logits.max(1)[1].cpu().numpy()\n",
        "        labels = data.y.cpu().numpy()\n",
        "\n",
        "\n",
        "    accuracy = accuracy_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()])\n",
        "\n",
        "\n",
        "    f1 = f1_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()], average='macro')\n",
        "\n",
        "\n",
        "    nmi = normalized_mutual_info_score(labels[data.test_mask.cpu()], preds[data.test_mask.cpu()])\n",
        "\n",
        "\n",
        "    G = to_networkx(data)\n",
        "    communities = {i: preds[i] for i in range(len(preds))}\n",
        "    community_list = [[] for _ in range(data.num_classes)]\n",
        "    for node, community in communities.items():\n",
        "        community_list[community].append(node)\n",
        "    modularity = nx.algorithms.community.modularity(G, community_list)\n",
        "\n",
        "    return accuracy, f1, nmi, modularity\n",
        "\n",
        "\n",
        "def load_data(dataset_name):\n",
        "    if dataset_name == 'KarateClub':\n",
        "        data = KarateClub(transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "    elif dataset_name == 'FacebookPagePage':\n",
        "        data = FacebookPagePage(root='/tmp/FacebookPagePage', transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "    else:\n",
        "        data = Planetoid(root=f'/tmp/{dataset_name}', name=dataset_name, transform=NormalizeFeatures())[0]\n",
        "        data.num_classes = len(set(data.y.tolist()))\n",
        "\n",
        "\n",
        "    num_nodes = data.y.size(0)\n",
        "    indices = np.random.permutation(num_nodes)\n",
        "    train_size = int(num_nodes * 0.6)\n",
        "    val_size = int(num_nodes * 0.2)\n",
        "    test_size = num_nodes - train_size - val_size\n",
        "\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "    train_mask[indices[:train_size]] = True\n",
        "    val_mask[indices[train_size:train_size + val_size]] = True\n",
        "    test_mask[indices[train_size + val_size:]] = True\n",
        "\n",
        "    data.train_mask = train_mask\n",
        "    data.val_mask = val_mask\n",
        "    data.test_mask = test_mask\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "datasets = ['KarateClub', 'Cora', 'Citeseer', 'FacebookPagePage']\n",
        "for dataset_name in datasets:\n",
        "    data = load_data(dataset_name)\n",
        "\n",
        "\n",
        "    model = HybridModel(gcn_input_dim=data.num_node_features, gcn_output_dim=32,\n",
        "                        rnn_input_dim=32, rnn_hidden_dim=64, rnn_num_layers=2, num_classes=data.num_classes)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    for epoch in range(180):\n",
        "        loss = train(model, data, optimizer, criterion)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "\n",
        "    accuracy, f1, nmi, modularity = evaluate(model, data)\n",
        "    print(f'{dataset_name} - Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, NMI: {nmi:.4f}, Modularity: {modularity:.4f}')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}